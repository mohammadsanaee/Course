{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadsanaee/Course/blob/main/1-Experiments-with-Architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fni0HZrYwdJ"
      },
      "source": [
        "# Task: Building the application for handwritten digits recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgKMaMMMTnas"
      },
      "source": [
        "## 1. Pytorch Lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWt0iuJbKdwY"
      },
      "source": [
        "### 1.0 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkgaFfs6ZHGc"
      },
      "source": [
        "**Pytorch Lightning** simplifies the programming process for training neural networks.\n",
        "\n",
        "Usually, when we program the learning process, we operate with standard procedures, regardless of the problem that we will solve. These procedures go in a certain sequence, which we will call a pipeline.\n",
        "\n",
        "For example, I can build a learning sequence like this:\n",
        "\n",
        "```\n",
        "1. Prepare and initialize the neural network, transfer it to\n",
        "     required device (gpu, cpu, tpu, npu)\n",
        "\n",
        "2. Prepare dataset\n",
        "\n",
        "3. Initialize optimizer\n",
        "\n",
        "4. Repeat n epochs:\n",
        "\n",
        "     4.1 Perform training on the training dataset during the epoch:\n",
        "         4.1.1 Take several examples (batch) from the dataset and preprocess them\n",
        "               so that they can be passed through the network,\n",
        "               transfer these examples to the one used in the learning process\n",
        "               device (gpu, cpu, tpu, npu)\n",
        "\n",
        "         4.1.2 Switch the neural network to learning mode (this is important if\n",
        "               neural network there are modules that work differently in\n",
        "               training and validation process, such as batch normalization)\n",
        "\n",
        "         4.1.3 Run a batch through the neural network and get the network's response to\n",
        "               teaching examples\n",
        "\n",
        "         4.1.4 Compare the result of the neural network with the target values\n",
        "               using the loss function\n",
        "\n",
        "         4.1.5 Zero out previously calculated weight gradients\n",
        "\n",
        "         4.1.6 Calculate new weight gradients using the inverse method\n",
        "               error propagation (loss.backward())\n",
        "\n",
        "         4.1.7 Make an optimizer step\n",
        "\n",
        "         4.1.8 Calculate metrics on the current batch\n",
        "\n",
        "         4.1.9 Update log, write learning status to file\n",
        "\n",
        "         4.1.10 Switch the network to validation mode (just in case, so that\n",
        "                statistics of batch normalizations were not accidentally spoiled somewhere)\n",
        "\n",
        "         4.1.11 Check if we have reached a plateau. If yes, then slow down\n",
        "                learning\n",
        "\n",
        "     4.2 Perform validation on the validation dataset (same as\n",
        "         training, but without optimization and without switching to training\n",
        "         mode):\n",
        "\n",
        "         4.2.1 ....\n",
        "         4.2.2 ....\n",
        "\n",
        "     4.3 Visualize several examples from the validation, training,\n",
        "         test dataset:\n",
        "\n",
        "         4.3.1 ....\n",
        "         4.3.2 ....\n",
        "\n",
        "     4.4 Save at the end of the epoch the weight of the model to a file, check if it is the best\n",
        "         model, if the model is the best, then save the weights to a file with the best weights.\n",
        "\n",
        "     4.5? ....\n",
        "\n",
        "5 ? ....\n",
        "```\n",
        "\n",
        "The model training process may differ from task to task, but most of the components are standard.\n",
        "\n",
        "If you write a very complex learning process with your hands, then you can make a random mistake (for example, very often programmers forget to switch between the training and test modes of the neural network, reset the gradients and make many other unpleasant errors). As a result, the neural network is trained incorrectly, and may not be trained at all. At the same time, it is extremely difficult to find such an error, since this is not a compilation error or division by 0: everything seems to work, but the result is not very good.\n",
        "\n",
        "**Pytorch Lightning** allows you not to write a large enough amount of code, automating the transfer of network and data to the GPU or TPU, switching between neural network modes, and adding fairly simple logging. In addition, there are a lot of useful plugins for training neural networks using PyTorch Lightning. Therefore, to solve full-fledged problems of Machine Learning, it is desirable to use this library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leg6cl0LTvgE"
      },
      "source": [
        "### 1.1 Library installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiGjexKubVKC"
      },
      "source": [
        "First, let's install PyTorch Lightning using the pip terminal command. Terminal commands can be used in Jupyter Notebooks and Colabs. To run a terminal command, you must precede the command with an exclamation mark. For example, to view the contents of a folder, you can use the ```!ls``` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3U4mXXKfx_o8"
      },
      "outputs": [],
      "source": [
        "!pip install -q pytorch-lightning\n",
        "\n",
        "# the -q flag allows you to significantly reduce the output when installing a package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUB-ipAtV0Y4"
      },
      "source": [
        "### 1.2 Imorting the modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_dqtXgrF9CS"
      },
      "source": [
        "In this practice, we will use several libraries. First is ```Pytorch Lightning```. In addition, we need ```Pytorch``` itself: we will use it to define neural networks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning==1.9.5"
      ],
      "metadata": {
        "id": "-F8yC8VG3AlC",
        "outputId": "d47c5a43-3cc4-48ab-d4ac-3e785943e157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning==1.9.5 in /usr/local/lib/python3.10/dist-packages (1.9.5)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.5) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.5) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.5) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.5) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.5) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.5) (0.11.4)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.5) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.5) (4.6.3)\n",
            "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.9.5) (0.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (2.27.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (3.8.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning==1.9.5) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->pytorch-lightning==1.9.5) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->pytorch-lightning==1.9.5) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->pytorch-lightning==1.9.5) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.9.5) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->pytorch-lightning==1.9.5) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E_UWTkhTxi2J"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TspNY0teVuRe"
      },
      "source": [
        "### 1.3 Reproducible training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWuo5OK7WZYl"
      },
      "source": [
        "In order to do A-B tests and gradually improve the learning process of the neural network, you need to make sure that the learning result is reproducible from run to run. Since pseudo-random numbers are often used in training neural networks, it is necessary that random number generators produce the same sequences from run to run. In addition, you need to switch CUDA to deterministic mode. This requirement reduces the speed of program execution, but the results of calculations become reproducible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sByl2X8OWhrJ",
        "outputId": "28d643dd-9d80-4adb-f6d0-c3fc036c3cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "seed=42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "pl.seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZZUkIX4T6Jk"
      },
      "source": [
        "## 2. Preparing data, dataset class and data loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXdzN3I3Kqc4"
      },
      "source": [
        "### 2.0 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfUFy_YTb722"
      },
      "source": [
        "In order to be able to pull out a training example by index and know how many training examples are contained in the dataset, a dataset is usually written. In this practice, we will use standard datasets, so we just need to initialize the standard objects of the **MNIST** class, which are implemented in the torchvision standard library.\n",
        "\n",
        "Below we initialize two datasets: training and test.\n",
        "\n",
        "In real life, for this it is necessary to implement some class that stores the data index (that is, information about where and how the data is stored), and also returns one training example upon request.\n",
        "\n",
        "In order to make a dataset class, you need to make a class with the following interface:\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "classDataset:\n",
        "     def __init__(self):\n",
        "         # Constructor code where it usually happens\n",
        "         # collecting an index about the dataset: paths to files,\n",
        "         # about how the data is related and\n",
        "         # etc.\n",
        "         #\n",
        "         # Here it is also worth setting augmentations,\n",
        "         # which will be used in the dataset.\n",
        "\n",
        "     def __len__(self):\n",
        "         # This method is required in order to be\n",
        "         # it is possible to get the number of elements in\n",
        "         # dataset using the len() method:\n",
        "         #\n",
        "         #len(dataset)\n",
        "         #\n",
        "         # This method is used by standard\n",
        "         # data loader classes in PyTorch.\n",
        "         #\n",
        "         # The method must return a number.\n",
        "\n",
        "     def __getitem__(self, index):\n",
        "         # This method loads one\n",
        "         # example from the dataset. Here is an image and\n",
        "         # the markup is read from disk and then normally\n",
        "         # are augmented.\n",
        "         #\n",
        "         # The method must return either a tuple,\n",
        "         # either a list or a dictionary. Preferably from\n",
        "         # torch tensors.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zYmlW8R4XeK"
      },
      "source": [
        "### 2.1 Dataset initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN0m0ec3eHFz"
      },
      "source": [
        "In this notebook, we will not write our own datasets, but will use those that are available in the `torchvision` auxiliary library. We will be interested in the `MNIST` dataset.\n",
        "\n",
        "1. Examine the interface of the `torchvision.datasets.MNIST` class. See what parameters this dataset can influence.\n",
        "\n",
        "2. Initialize training and test datasets (`torchvision.datasets.MNIST`).\n",
        "\n",
        "3. In the constructor, use the following parameters:\n",
        "     * augmentations from `torchvision.transforms`:\n",
        "         * `transforms.ToTensor()`\n",
        "         * `transforms.Normalize((0.1307,), (0.3081,))`\n",
        "\n",
        "     * `root` -- whatever you like\n",
        "     * analyze and set the rest of the arguments as you think is more correct. Do not forget that shuffling the dataset makes sense for the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rIczAZDQ5ed"
      },
      "source": [
        "#### Hint: Documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcAaBD7mQ953"
      },
      "source": [
        "To view the documentation of a function (or class constructor):\n",
        "\n",
        "1. Type the name of the function in the same way as it will be used in the code, but without brackets.\n",
        "2. Place a question mark `?` after the function name and\n",
        "3. execute the cell.\n",
        "\n",
        "A \"Help\" window will appear in the right window, where the documentation will be displayed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOotwBlCq1yH"
      },
      "source": [
        "#### Hint: dataset arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ2gpdmUq865"
      },
      "source": [
        "* example path: `root='MNIST/train.pt'` for train and `root='MNIST/test.pt'` for test\n",
        "* you need to set the `download=True` argument in order for the data to be downloaded from the server\n",
        "* in order for the data to be transformed into `torch.Tensor`, you must set the `transforms=transforms.ToTensor()` argument. With the same argument, you can configure various basic augmentations available in `torchvision.transforms`. In practice, these augmentations are not recommended. We will use `albumentations` in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLB9pVGrdsRP"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j8cyDu3RQG1V",
        "outputId": "4f7cd488-d8b7-4b13-f465-005796368db9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "## YOUR CODE HERE\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the image tensors\n",
        "])\n",
        "\n",
        "# Define the testing transforms\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the image tensors\n",
        "])\n",
        "\n",
        "# Create the CIFAR10 datasets with the respective transforms\n",
        "train_dataset = torchvision.datasets.CIFAR10('VOC', download=True, transform=train_transforms, train=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10('VOC', download=True, transform=test_transforms, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKyLg2xM9N8g",
        "outputId": "b1b55e5c-cfc9-4922-84aa-a9864e46a8a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n"
          ]
        }
      ],
      "source": [
        "#@title Unit Test\n",
        "\n",
        "# Checking the datasets classes\n",
        "assert(isinstance(train_dataset, torchvision.datasets.CIFAR10))\n",
        "assert(isinstance(test_dataset, torchvision.datasets.CIFAR10))\n",
        "\n",
        "# Checking volumes of the datasets\n",
        "assert(len(train_dataset) == 50000)\n",
        "assert(len(test_dataset) == 10000)\n",
        "\n",
        "# Checking outputs of the datasets\n",
        "assert(isinstance(train_dataset[0][0], torch.Tensor))\n",
        "assert(isinstance(train_dataset[0][1], int))\n",
        "\n",
        "# Checking dimentionalities\n",
        "assert(train_dataset[0][0].shape == torch.Size((3, 32, 32)))\n",
        "assert(train_dataset[0][1] == 6)\n",
        "\n",
        "print('OK')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_0GI7bIh_oc"
      },
      "source": [
        "#### Checking the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ41Nzp7612c"
      },
      "source": [
        "It is very important to check that the dataset works as it should. To do this, it is worth visualizing the picture if we are working with images, looking at the text if we are dealing with texts, or listening to the audio track if sound is being analyzed.\n",
        "\n",
        "You need to check that the image is displayed correctly, and also that the label, if any, matches the image.\n",
        "\n",
        "You should also pay attention to data sizes (the `.shape` method). Most of the errors can be found by analyzing only the size of the data.\n",
        "\n",
        "It's worth looking at some data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "X4hJ-43sgeKo",
        "outputId": "12ece7bd-d755-425a-ee40-d4161ce4a973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples in training and test dataset:\n",
            "50000 10000\n",
            "Image size. NOTE that number of channels comes first:\n",
            "torch.Size([3, 32, 32])\n",
            "Image class and class name:\n",
            "6 frog\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Number of examples in training and test dataset:')\n",
        "print(len(train_dataset), len(test_dataset))\n",
        "print('Image size. NOTE that number of channels comes first:')\n",
        "print(train_dataset[0][0].shape)\n",
        "plt.imshow(train_dataset[0][0][0]) # draw the image\n",
        "print('Image class and class name:')\n",
        "print(train_dataset[0][1], train_dataset.classes[train_dataset[0][1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqVoQYo3Fiwe"
      },
      "source": [
        "### 2.2 Creating data loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fH-VFCadTg7"
      },
      "source": [
        "The datasets are defined. In order to automatically extract from datasets\n",
        "batches (small bundles of data that are ready to be passed to the input of the neural network), there is a special class in pytorch: DataLoader (loader). It can be\n",
        "flexible enough to configure:\n",
        "\n",
        "* select the batch size to be\n",
        "pulled out of the DataLoader,\n",
        "\n",
        "* choose how many parallel processes to use for\n",
        "batch processing (this significantly reduces the time for data processing, including\n",
        "when augmentations are used).\n",
        "\n",
        "* shuffle data\n",
        "(this is useful for training data: then the batches that enter the network\n",
        "will vary).\n",
        "\n",
        "* discard last batch on load\n",
        "\n",
        "Discarding the last batch in the training dataset is very important,\n",
        "since it can be small, the statistics that are calculated from it can be\n",
        "unrepresentative. As a result, batch normalizations will be corrupted.\n",
        "To avoid this, the ```drop_last``` parameter is provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALud-qiffruc"
      },
      "source": [
        "#### Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZBqbLY_LYyl"
      },
      "source": [
        "Configure data loaders. Set: batch size 32, number of processing threads (workers) 8.\n",
        "\n",
        "Set the training data to random shuffle and discard the last batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51hZLnk1LcSJ"
      },
      "source": [
        "##### Hint: loader arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezsoPcYrLfyN"
      },
      "source": [
        "For the training dataset, set:\n",
        "* `batch_size` equal to `32`\n",
        "* `num_workers` to `8`\n",
        "* `shuffle` to `True`\n",
        "* `drop_last` to `True`\n",
        "\n",
        "For a test dataset, set:\n",
        "* `batch_size` equal to `32`\n",
        "* `num_workers` to `8`\n",
        "* `shuffle` to `False`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFjF5lk7MFTT"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cyMuUgQodQcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87bc9e6-efc4-4986-f37c-12104c5b4819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset,batch_size = 32, shuffle = True, num_workers = 8, drop_last = True) #YOUR CODE HERE\n",
        "test_loader  = DataLoader(test_dataset,batch_size = 32, shuffle = False, num_workers = 8) #YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtOO1GnOOEWj"
      },
      "source": [
        "## 3. Defining the error function and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS9UeP4eOSCo"
      },
      "source": [
        "### 3.1 Loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVuVhBtjcTG"
      },
      "source": [
        "For any task, it is necessary to define a loss function, with the help of which the model will be trained. The loss function can be set by hand, or you can use a ready-made one.\n",
        "\n",
        "In this practice, we will use the already implemented loss function: ```torch.nn.CrossEntropyLoss```.\n",
        "\n",
        "We will do this in the first place because this loss function combines `torch.nn.SoftMax` and the cross-entropy `torch.nn.NLLloss` itself, which prevents numerical instability when calculating the loss. It is rare, but in some cases it can spoil the learning process.\n",
        "\n",
        "In case you need to use some custom loss function, you can implement the `loss` function, which will return a `torch.Tensor` consisting of a single number. This is important so that you can later use `backward` for gradient calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nE3JOaOeIM"
      },
      "source": [
        "#### Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfO2dlsaOf_P"
      },
      "source": [
        "Initialize the loss ```torch.nn.CrossEntropyLoss```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpP4pHsjg-0Y"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RJGGQWwiwHi4"
      },
      "outputs": [],
      "source": [
        "loss = torch.nn.CrossEntropyLoss() # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u89Q_Ihk7__i",
        "outputId": "a0bb0a40-353f-4f0a-a619-76154dee07d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n"
          ]
        }
      ],
      "source": [
        "#@title Unit Test\n",
        "import torch\n",
        "\n",
        "for index in range(1000):\n",
        "    x = torch.randn([10, 10])\n",
        "    y = torch.randint(0, 10, size=[10])\n",
        "\n",
        "    assert((loss(x, y) - torch.nn.functional.cross_entropy(x, y)).abs().mean() < 1.0e-8)\n",
        "\n",
        "print('OK')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38Az-VUQOvAU"
      },
      "source": [
        "### 3.2 Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UmZ1JZ_q5zm"
      },
      "source": [
        "For a normal person, loss is not informative. In order for us to understand how well or poorly the model actually works, we need to decide on a metric. We will use the \"accuracy\" metric.\n",
        "\n",
        "To calculate metrics, there is a library [torchmetrics] (https://github.com/PyTorchLightning/metrics). We will use this library in our projects.\n",
        "\n",
        "In order to implement a metric for PyTorch Lightning, you need to implement a class inherited from `trochmetrics.Metrics`, in which to implement three methods:\n",
        "\n",
        "* ```__init__(self)``` -- constructor. In the constructor, you must initialize the parent class with ```super().__init__()```. It is also necessary to initialize all auxiliary variables here (in our case, the ```correct``` fields, the number of correctly guessed objects, and the ```total``` field, the total number of classified objects). Variables must be declared in a special way: using the ```self.add_state``` method. For example, to define a field ```correct```, you need to write in the constructor: ```self.add_state(\"correct\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")```. The last parameter is needed for multi-threaded learning.\n",
        "\n",
        "* ```update(self, preds, targets)``` -- update when new neural network results are received. The input is tensors with the results of the network and target variables (batches). Usually this method is to update auxiliary variables. In our case, we need to add the number of guessed data to ```self.correct``` and the total number of objects in the batch to ```self.total```, which were declared in the constructor. Shouldn't return anything.\n",
        "\n",
        "* ```compute(self)``` is a method that calculates the metric value from auxiliary variables. In our case -- divides ```self.correct``` by ```self.total```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sgr3wzOS0pqA"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "\n",
        "class Accuracy(torchmetrics.Metric):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.add_state(\"correct\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
        "      self.add_state(\"total\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
        "\n",
        "    def update(self, preds, target):\n",
        "        self.correct += torch.sum(preds.argmax(dim=1)==target).item()\n",
        "        self.total += target.numel()\n",
        "\n",
        "    def compute(self):\n",
        "        return self.correct/self.total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z38_i1k1ft6",
        "outputId": "a7abfe6d-09c2-4e56-88e3-e174afb8caf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n"
          ]
        }
      ],
      "source": [
        "#@title Unit test\n",
        "\n",
        "correct = 0\n",
        "all = 0\n",
        "\n",
        "acc = Accuracy()\n",
        "\n",
        "for index in range(1000):\n",
        "    preds = torch.randn([1000, 100])\n",
        "    targs = torch.randint(0, 100, size=[1000])\n",
        "    acc.update(preds, targs)\n",
        "\n",
        "    correct += (preds.argmax(dim=1) == targs).float().sum()\n",
        "    all += targs.numel()\n",
        "\n",
        "    assert((acc.compute() - correct / all).abs().mean() < 1.0e-8)\n",
        "\n",
        "# acc.update(preds, targs)\n",
        "# assert(acc.compute() == 1.0 / 3.0)\n",
        "\n",
        "print('OK')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y8Jk4hFn7qo"
      },
      "source": [
        "## 4. Building the network and getting ready to train it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3K9vX8XxhQs"
      },
      "source": [
        "### 4.1. Architecture preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmwyUvjCeWNv"
      },
      "source": [
        "#### Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1bh9ZPY2SL4"
      },
      "source": [
        "We will make a simple two-layer fully connected network and train it. This network will have the following modules:\n",
        "\n",
        "```\n",
        "*BatchNorm1d\n",
        "Linear 28 * 28 -> n_hidden\n",
        "activation: ReLU, LeakyReLU, ELU, Tanh\n",
        "*BatchNorm1d\n",
        "Linear n_hidden -> 10\n",
        "```\n",
        "\n",
        "In order to make a neural network architecture, it is necessary to define a class inherited from `torch.Module`, in which the following methods must be defined:\n",
        "\n",
        "* ```__init__(self)``` -- constructor to define the neural network modules to be used (same as in PyTorch). In addition, here it is necessary to initialize the classes of metrics and loss functions. Before declaring modules, you must call ```super().__init__()``` to initialize the parent class that provides the main functionality.\n",
        "\n",
        "* ```forward(self, input)``` -- pass through the network forward. Here you need to make predictions from ```input``` using modules defined in the constructor (nothing special here either, just like in PyTorch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD-5rFJ0eakB"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wG7sKsGr0g80"
      },
      "outputs": [],
      "source": [
        "# import torch.nn as nn\n",
        "# class Network(torch.nn.Module):\n",
        "\n",
        "#     def __init__(self,n_hidden):\n",
        "#         super().__init__()\n",
        "#          # YOUR CODE HERE\n",
        "#         # n_hidden = 64\n",
        "#         self.batchnorm1 = nn.BatchNorm1d(28*28)\n",
        "#         self.linear1 = nn.Linear(28*28,n_hidden)\n",
        "#         self.activation = nn.LeakyReLU()\n",
        "#         self.batchnorm2 = nn.BatchNorm1d(n_hidden)\n",
        "#         self.linear2 = nn.Linear(n_hidden,10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#          # YOUR CODE HERE\n",
        "#          x = x.view(x.size(0), -1)\n",
        "#          x = self.batchnorm1(x)\n",
        "#          x = self.linear1(x)\n",
        "#          x = self.activation(x)\n",
        "#          x = self.batchnorm2(x)\n",
        "#          x = self.linear2(x)\n",
        "#          return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GQjTPgoN2ZRa"
      },
      "outputs": [],
      "source": [
        "# #@title Unit test\n",
        "\n",
        "# x = torch.zeros(10, 1, 28, 28)\n",
        "# net = Network(64)\n",
        "# res = net.forward(x)\n",
        "\n",
        "# print('OK')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XllTf9FCxudA"
      },
      "source": [
        "### 4.2. Preparing the Pytorch Lightning Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4hLn2tX2KWY"
      },
      "source": [
        "In order to prepare the network for training on PyTorch Lightning, you need to make a class inherited from ```pl.LightningModule```.\n",
        "\n",
        "In this class, you need to define:\n",
        "* As in PyTorch:\n",
        "     * `__init__(self)`\n",
        "     * `forward(self, x)`\n",
        "\n",
        "In our case, for convenience, it makes sense to initialize the `self.model` Pytorch field in `__init__` with the model specified earlier, and use the same method from `self.model` in the forward method.\n",
        "\n",
        "* Minimal kit for PyTorch Lightning:\n",
        "   * ```training_step(self, batch, batch_idx)``` -- here, from network predictions made using the forward method, loss functions and metrics are calculated and logged. In order to log some value, you need to do: ```self.log('name_of_value/train', value, on_epoch=True)``` The function must return the value of the loss.\n",
        "   * ```configure_optimizers(self)```. This is where the optimizers must be defined. For example, I can define an optimizer like this: ```optim = torch.optim.Adam(self.parameters(), lr=1.0e-3)```. It is also convenient to define schedulers for optimizers here. For example, a scheduler could be defined like this: ```sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='max', factor=0.3, verbose=True)```. The function must return a list of optimizers or a single optimizer (if there is only one optimizer).\n",
        "\n",
        "* In order to be able to calculate the metrics for validation, we will also implement\n",
        "   * ```validation_step(self, batch, batch_idx)``` -- same as training_step, only for validation set. This function may not return anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YQKUI7-eyIY"
      },
      "source": [
        "#### Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVdK2rmFe1Wz"
      },
      "source": [
        "Populate the Pytorch Lightning class as described above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiRHkP_kfCaO"
      },
      "source": [
        "#### VGG Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNormAct(torch.nn.Module):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.module = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(*args, **kwargs),\n",
        "            torch.nn.BatchNorm2d(args[1]),\n",
        "            torch.nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.module.forward(input)\n",
        "\n",
        "\n",
        "class VGG(torch.nn.Module):\n",
        "    def __init__(self, act=torch.nn.LeakyReLU):\n",
        "        super().__init__()\n",
        "        self.conv_modules = torch.nn.Sequential(\n",
        "            ConvNormAct(3, 32, 3, padding=1), #  Stem: ConvNormAct 3 -> 32\n",
        "            ## block 1\n",
        "            ConvNormAct(32, 32, 3, padding=1),\n",
        "            ConvNormAct(32, 64, 3, padding=1),\n",
        "            torch.nn.MaxPool2d(2),\n",
        "            ## block 2\n",
        "            ConvNormAct(64, 64, 3, padding=1),\n",
        "            ConvNormAct(64, 128, 3, padding=1),\n",
        "            torch.nn.MaxPool2d(2),\n",
        "            ## block 3\n",
        "            ConvNormAct(128, 128, 3, padding=1),\n",
        "            ConvNormAct(128, 256, 3, padding=1),\n",
        "            torch.nn.MaxPool2d(2),\n",
        "            ## block 4\n",
        "            ConvNormAct(256, 256, 3, padding=1),\n",
        "            ConvNormAct(256, 256, 3, padding=1),\n",
        "            torch.nn.MaxPool2d(2)\n",
        "\n",
        "        )\n",
        "        self.global_avg_pool = torch.nn.AdaptiveAvgPool2d([1, 1])\n",
        "        self.classifier = torch.nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, input):\n",
        "        res = input\n",
        "        res = self.conv_modules(res)\n",
        "        res = res.mean(dim=[-1, -2])\n",
        "        res = self.classifier(res)\n",
        "        return res"
      ],
      "metadata": {
        "id": "AvM9ERmJ-vXc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### RESNET"
      ],
      "metadata": {
        "id": "MZDiN9ZzLIKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(torch.nn.Module):\n",
        "    def __init__(self, module, bypass=torch.nn.Identity()):\n",
        "        super().__init__()\n",
        "        self.module = module\n",
        "        self.bypass = bypass\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.module(input) + self.bypass(input)\n",
        "\n",
        "class ResNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_net = torch.nn.Sequential(\n",
        "            ConvNormAct(3, 32, 3, padding=1), # stem\n",
        "\n",
        "            # block 1 32x32\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(32, 8, 3, padding=1),\n",
        "                    ConvNormAct(8, 32, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(32, 8, 3, padding=1),\n",
        "                    ConvNormAct(8, 32, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(32, 8, 3, padding=1),\n",
        "                    ConvNormAct(8, 32, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(32, 8, 3, padding=1),\n",
        "                    ConvNormAct(8, 32, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(32, 16, 3, stride=2, padding=1),\n",
        "                    ConvNormAct(16, 64, 3, padding=1)),\n",
        "                    bypass=torch.nn.Conv2d(32, 64, 1, stride=2)),\n",
        "\n",
        "            # block 2\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(64, 16, 3, padding=1),\n",
        "                    ConvNormAct(16, 64, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(64, 16, 3, padding=1),\n",
        "                    ConvNormAct(16, 64, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(64, 16, 3, padding=1),\n",
        "                    ConvNormAct(16, 64, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(64, 16, 3, padding=1),\n",
        "                    ConvNormAct(16, 64, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(64, 32, 3, stride=2, padding=1),\n",
        "                    ConvNormAct(32, 128, 3, padding=1)),\n",
        "                    bypass=torch.nn.Conv2d(64, 128, 1, stride=2)),\n",
        "            # block 3\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(128, 32, 3, padding=1),\n",
        "                    ConvNormAct(32, 128, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(128, 32, 3, padding=1),\n",
        "                    ConvNormAct(32, 128, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(128, 32, 3, padding=1),\n",
        "                    ConvNormAct(32, 128, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(128, 32, 3, padding=1),\n",
        "                    ConvNormAct(32, 128, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(128, 32, 3, stride=2, padding=1),\n",
        "                    ConvNormAct(32, 256, 3, padding=1)),\n",
        "                    bypass=torch.nn.Conv2d(128, 256, 1, stride=2)),\n",
        "            # block 4\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(256, 64, 3, padding=1),\n",
        "                    ConvNormAct(64, 256, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(256, 64, 3, padding=1),\n",
        "                    ConvNormAct(64, 256, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(256, 64, 3, padding=1),\n",
        "                    ConvNormAct(64, 256, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(256, 64, 3, padding=1),\n",
        "                    ConvNormAct(64, 256, 3, padding=1))),\n",
        "            ResBlock(\n",
        "                torch.nn.Sequential(\n",
        "                    ConvNormAct(256, 64, 3, padding=1, stride=2),\n",
        "                    ConvNormAct(64, 256, 3, padding=1)),\n",
        "                    bypass=torch.nn.Conv2d(256, 256, 1, stride=2)),\n",
        "        )\n",
        "        self.classifier = torch.nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, input):\n",
        "        res = input\n",
        "        res = self.conv_net(res)\n",
        "        res = res.mean(dim=[-1, -2])\n",
        "        res = self.classifier(res)\n",
        "        return res"
      ],
      "metadata": {
        "id": "Yx-Z5jW7LG4G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU CONV NET"
      ],
      "metadata": {
        "id": "mAU4n9eQghLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUx(torch.nn.Module):\n",
        "  def __init__(self,in_ch,out_ch):\n",
        "    super().__init__()\n",
        "    self.module = torch.nn.GRU(in_ch,out_ch,bidirectional = True)\n",
        "\n",
        "  def forward(self,input):\n",
        "    batch_size = input.shape[0]\n",
        "    IMG = input\n",
        "    IMG = IMG.permute([2, 1, 0, 3])\n",
        "    IMG = IMG.reshape([IMG.shape[0], IMG.shape[1], -1])\n",
        "    IMG = IMG.permute([0, 2, 1])\n",
        "    res,memo = self.module(IMG)\n",
        "    res = res.permute([0,2,1])\n",
        "    res = res.reshape([res.shape[0], res.shape[1],batch_size,-1])\n",
        "    res = res.permute([2,1,0,3])\n",
        "    return res\n",
        "\n",
        "class GRUy(torch.nn.Module):\n",
        "  def __init__(self,in_ch,out_ch):\n",
        "    super().__init__()\n",
        "    self.module = torch.nn.GRU(in_ch,out_ch,bidirectional = True)\n",
        "\n",
        "  def forward(self,input):\n",
        "    batch_size = input.shape[0]\n",
        "    IMG = input\n",
        "    IMG = IMG.permute([3, 1, 0, 2])\n",
        "    IMG = IMG.reshape([IMG.shape[0], IMG.shape[1], -1])\n",
        "    IMG = IMG.permute([0, 2, 1])\n",
        "    res,memo = self.module(IMG)\n",
        "    res = res.permute([0,2,1])\n",
        "    res = res.reshape([res.shape[0], res.shape[1],batch_size,-1])\n",
        "    res = res.permute([2,1,0,3])\n",
        "    return res\n",
        "\n",
        "class GRU_conv(torch.nn.Module):\n",
        "  def __init__(self,in_ch,out_ch,m_ch):\n",
        "    super().__init__()\n",
        "    self.GRUX = GRUx(in_ch,m_ch)\n",
        "    self.GRUY = GRUy(in_ch,m_ch)\n",
        "    self.out_conv = torch.nn.Conv2d(4*m_ch,out_ch,1)\n",
        "\n",
        "  def forward(self,input):\n",
        "    res = input\n",
        "    x_res = self.GRUX.forward(res)\n",
        "    y_res = self.GRUY.forward(res)\n",
        "    res = torch.cat([x_res, y_res], dim=1) # problem\n",
        "    res = self.out_conv(res)\n",
        "    return res\n",
        "\n",
        "class GRU_VGG(torch.nn.Module):\n",
        "  def __init__(self,activation = torch.nn.LeakyReLU):\n",
        "    super().__init__()\n",
        "    self.conv_module = torch.nn.Sequential(\n",
        "        ConvNormAct(3, 32, 3, padding=1),\n",
        "        #Block1\n",
        "        GRU_conv(32,32,32),\n",
        "        GRU_conv(32,64,64),\n",
        "        torch.nn.MaxPool2d(2),\n",
        "        #Block2\n",
        "        GRU_conv(64,64,64),\n",
        "        GRU_conv(64,128,128),\n",
        "        torch.nn.MaxPool2d(2),\n",
        "        #Block3\n",
        "        GRU_conv(128,128,128),\n",
        "        GRU_conv(128,256,256),\n",
        "        torch.nn.MaxPool2d(2),\n",
        "        #Blcok4\n",
        "        GRU_conv(256,256,256),\n",
        "        GRU_conv(256,256,256),\n",
        "\n",
        "    )\n",
        "    self.global_avg_pool = torch.nn.AdaptiveAvgPool2d([1, 1])\n",
        "    self.classifier = torch.nn.Linear(256, 10)\n",
        "  def forward(self,input):\n",
        "    res = input\n",
        "    res = self.conv_module(res)\n",
        "    res = res.mean(dim = [-1,-2])\n",
        "    res = self.classifier(res)\n",
        "    return res"
      ],
      "metadata": {
        "id": "ZwJOq11Hggg2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unit test\n",
        "\n",
        "x = torch.zeros(10, 3, 32, 32)\n",
        "net = VGG()\n",
        "res = net.forward(x)\n",
        "\n",
        "print('OK')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shwbM6CGBLfE",
        "outputId": "a5b6adee-6792-4e4d-b562-1e0c930816a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unit test\n",
        "\n",
        "x = torch.zeros(10, 3, 32, 32)\n",
        "net = ResNet()\n",
        "res = net.forward(x)\n",
        "\n",
        "print('OK')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9iRkDUTOGtZ",
        "outputId": "a5bd7c96-7929-4be3-81fd-69d286bf6bf2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unit test\n",
        "\n",
        "x = torch.zeros(10, 3, 32, 32)\n",
        "net = GRU_VGG()\n",
        "res = net.forward(x)\n",
        "\n",
        "print('OK')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fe7f47-65a2-47a3-e370-105c8973fdf4",
        "id": "6t3oj6REoiUQ"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "it4FyRtex8tG"
      },
      "outputs": [],
      "source": [
        "class PLModel(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "\n",
        "      super().__init__()\n",
        "       # YOUR CODE HERE\n",
        "      self.model = model\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "      return self.model(input) # YOUR CODE HERE\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "       # YOUR CODE HERE\n",
        "      x,y = batch\n",
        "      pred = self.model(x)\n",
        "      loss_value = loss(pred,y)\n",
        "      self.log('train_loss', loss_value,on_epoch=True)\n",
        "      return loss_value\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "      # YOUR CODE HERE\n",
        "      x,y = batch\n",
        "      pred = self.model(x)\n",
        "      # acc.update(preds, y)\n",
        "      # val_accuracy = acc.compute()\n",
        "      val_accuracy=acc(pred,y)\n",
        "      self.log('val_accuracy', val_accuracy, on_epoch=True)\n",
        "      return val_accuracy\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "       # YOUR CODE HERE\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=1.0e-3)\n",
        "      # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.3, verbose=True)\n",
        "      return [optimizer]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO98eT5ix7jT"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9URMzgnyCJa"
      },
      "source": [
        "### 5.1. TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6YpLvwDiJf_"
      },
      "source": [
        "**Tensorboard** is the standard way to track learning progress. In TensorBoard, you can plot metrics and loss functions, draw pictures and track how they change over time. PyTorch Lightning automatically writes logs to TensorBoard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qiF7pCOyGgJ"
      },
      "source": [
        "### 5.2. Start training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNJwnOpWi8jm"
      },
      "source": [
        "By default, Pytorch Lightning uses not the most convenient and informative progress bar. Therefore, below we have made a more interesting progress bar, which allows you to track the learning process more conveniently and does not load the browser."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(str(datetime.time()))"
      ],
      "metadata": {
        "id": "sPkuRzb4Okzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f320e0b-2ae6-4303-b158-be5636dfaa7e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "cellView": "form",
        "id": "UxHlhI6txWBo"
      },
      "outputs": [],
      "source": [
        "#@title Custom ProgressBar Code (Code is complex and irrelevant to the task)\n",
        "\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "import datetime\n",
        "import copy\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from IPython.display import display, update_display\n",
        "except:\n",
        "    pass\n",
        "\n",
        "def isnotebook():\n",
        "    try:\n",
        "        shell = get_ipython().__class__.__name__\n",
        "        module = get_ipython().__class__.__module__\n",
        "        if module == \"google.colab._shell\":\n",
        "            return True\n",
        "        if shell == 'ZMQInteractiveShell':\n",
        "            return True   # Jupyter notebook or qtconsole\n",
        "        elif shell == 'TerminalInteractiveShell':\n",
        "            return False  # Terminal running IPython\n",
        "        else:\n",
        "            return False  # Other type (?)\n",
        "    except NameError:\n",
        "        return False\n",
        "\n",
        "def nlines(text):\n",
        "    return text.count('\\n') + 1\n",
        "\n",
        "status = {\n",
        "    'Info': '5/10 [######9     ] 59%',\n",
        "    'Time/D': 0.9999999999999999999999,\n",
        "    'Time/B': 0.1238476123864126345187245,\n",
        "    'Time/AvgD': 0.812341348176234987162349817643,\n",
        "    'Time/AvgB': 0.8561283745187634581726345,\n",
        "    'Loss/L1': 112398746192834619827364,\n",
        "    'Loss/L2': 19234618623.0,\n",
        "    'Loss/L2.5': 1,\n",
        "    'Loss/L3': 0.8126347152,\n",
        "    'Loss/L4': 10,\n",
        "    'Loss/L5': numpy.inf,\n",
        "    'Metrics/One': 0.888888,\n",
        "    'Metrics/Two': 123987.0,\n",
        "    'Metrics/Three': 1.0\n",
        "}\n",
        "\n",
        "\n",
        "def textcolor(style=None, color=None):\n",
        "    if color is None:\n",
        "        color = 0\n",
        "    else:\n",
        "        color_code = 30 + color\n",
        "    if style is None:\n",
        "        style_code = 0\n",
        "    else:\n",
        "        style_code = style\n",
        "    return '\\033[' + str(style_code) + ';' + str(color_code) + 'm', '\\033[' + str(0) + ';' + str(0) + 'm'\n",
        "\n",
        "\n",
        "def format_status(inp):\n",
        "    if isinstance(inp, (dict)):\n",
        "        for key in inp:\n",
        "            inp[key] = format_status(inp[key])\n",
        "\n",
        "    if isinstance(inp, (list, tuple)):\n",
        "        for index in range(len(inp)):\n",
        "            inp[index] = format_status(inp[index])\n",
        "\n",
        "    if isinstance(inp, torch.Tensor):\n",
        "        inp = inp.detach().cpu().numpy()\n",
        "\n",
        "    if isinstance(inp, int):\n",
        "        if abs(inp) > 10 ** 6:\n",
        "            return '{:.3e}'.format(inp)\n",
        "        else:\n",
        "            return '{:d}'.format(inp)\n",
        "\n",
        "    if isinstance(inp, float):\n",
        "        if abs(inp) > 10 ** 6:\n",
        "            return '{:.3e}'.format(inp)\n",
        "        elif abs(inp) < 10 ** -6:\n",
        "            return '{:.3e}'.format(inp)\n",
        "        else:\n",
        "            return '{:.6f}'.format(inp)\n",
        "\n",
        "    return inp\n",
        "\n",
        "\n",
        "def colorize_string(string, colors, padding=0):\n",
        "    indice = []\n",
        "    for color in colors:\n",
        "        indice.append(colors[0])\n",
        "\n",
        "    substrings = []\n",
        "    last_index = 0\n",
        "    for color in colors:\n",
        "        index = color[0] + padding\n",
        "        substrings.append(string[last_index:index])\n",
        "        substrings.append(color[1])\n",
        "        last_index = index\n",
        "    substrings.append(string[last_index:])\n",
        "    return ''.join(substrings)\n",
        "\n",
        "\n",
        "def view_status(inp, display_len=80):\n",
        "    separator = ' | '\n",
        "    strings = ['']\n",
        "    colors = [[]]\n",
        "    color_index = 0\n",
        "\n",
        "    maxlen = 0\n",
        "    for key in inp:\n",
        "        maxlen = max(len(str(key)), maxlen)\n",
        "\n",
        "    for key in inp:\n",
        "\n",
        "        start, end = textcolor(style=1, color=color_index + 1)\n",
        "        colors[-1].append((len(strings[-1]), start))\n",
        "        strings[-1] += ('{:>' + str(maxlen) + 's} ').format(key)\n",
        "        colors[-1].append((len(strings[-1]), end))\n",
        "\n",
        "        if isinstance(inp[key], (list, tuple)):\n",
        "            strings[-1] += separator.join(inp[key])\n",
        "\n",
        "        elif isinstance(inp[key], dict):\n",
        "            pos = len(strings[-1])\n",
        "            subres = []\n",
        "\n",
        "            for subkey in inp[key]:\n",
        "                start, end = textcolor(style=3, color=color_index + 1)\n",
        "                colors[-1].append((pos, start))\n",
        "                colors[-1].append((pos + len(subkey), end))\n",
        "                subres.append(subkey + ': ' + str(inp[key][subkey]))\n",
        "                pos = pos + len(subkey) + len(': ') + len(str(inp[key][subkey])) + len(separator)\n",
        "            strings[-1] += separator.join(subres)\n",
        "\n",
        "        else:\n",
        "            strings[-1] += str(inp[key])\n",
        "\n",
        "        strings.append('')\n",
        "        colors.append([])\n",
        "\n",
        "        color_index += 1\n",
        "        color_index %= 6\n",
        "\n",
        "    new_strings = []\n",
        "    new_colors = []\n",
        "    new_strings.append('=' * display_len)\n",
        "    for index in range(len(strings)):\n",
        "        string = strings[index]\n",
        "        str_colors = colors[index]\n",
        "        position = 0\n",
        "        color_index = 0\n",
        "        padding = 0\n",
        "        while len(string) > 0:\n",
        "            splitter_location = -1\n",
        "\n",
        "            if len(string) > display_len:\n",
        "                splitter_location = string[:display_len].rfind(' | ')\n",
        "\n",
        "            split_colors = []\n",
        "\n",
        "            if splitter_location > 0:\n",
        "                string_end = splitter_location\n",
        "            else:\n",
        "                string_end = min(display_len, len(string))\n",
        "            while color_index < len(colors[index]) and colors[index][color_index][0] - position < string_end - padding:\n",
        "                split_colors.append(list(colors[index][color_index]))\n",
        "                split_colors[-1][0] -= position\n",
        "                color_index += 1\n",
        "\n",
        "            if len(string) < display_len:\n",
        "                to_print = string\n",
        "                to_print = to_print + ' ' * (display_len - len(to_print))\n",
        "                new_strings.append(colorize_string(to_print, split_colors, padding=padding))\n",
        "                break\n",
        "\n",
        "            elif splitter_location > 0:\n",
        "                to_print = string[:splitter_location]\n",
        "                to_print = to_print + ' ' * (display_len - len(to_print))\n",
        "                new_strings.append(colorize_string(to_print, split_colors, padding=padding))\n",
        "                split_colors = []\n",
        "                string = ' ' * (maxlen + 1) + string[splitter_location + 3:]\n",
        "                position += splitter_location + 3 - padding\n",
        "                padding = maxlen + 1\n",
        "\n",
        "            else:\n",
        "                to_print = string[:string_end]\n",
        "                to_print = to_print + ' ' * (display_len - len(to_print))\n",
        "                new_strings.append(colorize_string(to_print, split_colors, padding=padding))\n",
        "                split_colors = []\n",
        "                string = ' ' * (maxlen + 1) + string[string_end:]\n",
        "                position += string_end - padding\n",
        "                padding = maxlen + 1\n",
        "\n",
        "    new_strings.append('=' * display_len)\n",
        "    return '\\n'.join(new_strings)\n",
        "\n",
        "\n",
        "def dict_to_multidict(status):\n",
        "    decomposed_status = {}\n",
        "    for key in list(status.keys()):\n",
        "        key_parts = key.split('/')\n",
        "        if len(key_parts) > 2:\n",
        "            continue\n",
        "\n",
        "        if len(key_parts) > 1:\n",
        "            superkey = key_parts[0]\n",
        "            subkey = '/'.join(key_parts[1:])\n",
        "\n",
        "            if superkey not in decomposed_status:\n",
        "                decomposed_status[superkey] = {}\n",
        "\n",
        "            decomposed_status[superkey][subkey] = status[key]\n",
        "        else:\n",
        "            decomposed_status[key] = status[key]\n",
        "\n",
        "    return decomposed_status\n",
        "\n",
        "\n",
        "def isnotebook():\n",
        "    try:\n",
        "        shell = get_ipython().__class__.__name__\n",
        "        module = get_ipython().__class__.__module__\n",
        "        if module == \"google.colab._shell\":\n",
        "            return True\n",
        "        if shell == 'ZMQInteractiveShell':\n",
        "            return True   # Jupyter notebook or qtconsole\n",
        "        elif shell == 'TerminalInteractiveShell':\n",
        "            return False  # Terminal running IPython\n",
        "        else:\n",
        "            return False  # Other type (?)\n",
        "    except NameError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def nlines(text):\n",
        "    return text.count('\\n') + 1\n",
        "\n",
        "\n",
        "def get_width():\n",
        "    try:\n",
        "        return os.get_terminal_size()[0] - 1\n",
        "    except :\n",
        "        return 100\n",
        "\n",
        "\n",
        "\n",
        "class StageProgressBar:\n",
        "    def __init__(self, width_function=None, display_id='ep{}'.format(0), is_ipython=None):\n",
        "        self.width_function = width_function\n",
        "\n",
        "\n",
        "        self.last_vals = None\n",
        "        self.finalized = False\n",
        "        self.started = False\n",
        "\n",
        "        self.is_ipython = isnotebook() if is_ipython is None else is_ipython\n",
        "        self.display_id = display_id\n",
        "\n",
        "    def __str__(self):\n",
        "        status = format_status(self.last_vals)\n",
        "        to_view = view_status(dict_to_multidict(status), display_len=self.width)\n",
        "        return to_view\n",
        "\n",
        "    def display(self, content):\n",
        "        if not self.is_ipython:\n",
        "            print(content, end='')\n",
        "            print('\\033[' + str(nlines(content)) + 'A')\n",
        "        else:\n",
        "            # print(self.display_id)\n",
        "            update_display({'text/plain': content}, display_id=self.display_id, raw=True)\n",
        "\n",
        "    def __del__(self):\n",
        "        self.finalize()\n",
        "\n",
        "    def update(self, vals):\n",
        "        if self.finalized:\n",
        "            return\n",
        "\n",
        "        self.width = self.width_function()\n",
        "        self.last_vals = vals\n",
        "        cur_info = str(self)\n",
        "\n",
        "        if not self.started:\n",
        "            self.started = True\n",
        "            if self.is_ipython:\n",
        "                print(self.display_id, '<- display_id')\n",
        "                display({'text/plain': ''}, display_id=self.display_id, raw=True)\n",
        "\n",
        "        self.display(cur_info)\n",
        "\n",
        "    def finalize(self):\n",
        "        if (not self.finalized) and (not self.is_ipython):\n",
        "            print(str(self))\n",
        "\n",
        "def progress_str(width, state):\n",
        "    progress = width * state\n",
        "    filled = int(math.floor(progress))\n",
        "\n",
        "    if filled < width:\n",
        "        remnant = str(int(math.floor((progress - filled) * 10.0)))\n",
        "        return '[' + '='* filled + remnant + ' ' * (width - filled - 1) + ']'\n",
        "    else:\n",
        "        return '[' + '=' * width + ']'\n",
        "\n",
        "class TimeEstimator:\n",
        "    def __init__(self, eta_threshold=0.001):\n",
        "        self.eta_threshold = eta_threshold\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.start_time = time.time()\n",
        "        self.cur_state = 0\n",
        "        self.est_finish_time = None\n",
        "        return self\n",
        "\n",
        "    def update(self, cur_state):\n",
        "        self.cur_state = cur_state\n",
        "        if self.cur_state >= self.eta_threshold:\n",
        "            self.est_finish_time = self.start_time + (time.time() - self.start_time) / self.cur_state\n",
        "\n",
        "    def __str__(self):\n",
        "        elapsed = str(datetime.timedelta(seconds=int(time.time() - self.start_time)))\n",
        "        if self.est_finish_time is not None:\n",
        "            eta = str(datetime.timedelta(seconds=int(self.est_finish_time - time.time())))\n",
        "        else:\n",
        "            eta = '?'\n",
        "\n",
        "        return f'[{elapsed}>{eta}]'\n",
        "\n",
        "\n",
        "class LiteProgressBar(pl.callbacks.ProgressBarBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.last_epoch = 0\n",
        "        self.pbar = StageProgressBar(width_function=get_width, display_id='ep{}'.format(0))\n",
        "        self.timer = TimeEstimator()\n",
        "        self.display_counter = 0\n",
        "\n",
        "    def disable(self):\n",
        "        self.enable = False\n",
        "\n",
        "    def on_train_epoch_start(self, *args, **kwargs):\n",
        "        super().on_train_epoch_start(*args, **kwargs)\n",
        "        self.timer.reset()\n",
        "        trainer = args[0]\n",
        "        log = copy.deepcopy(trainer.logged_metrics)\n",
        "        if 'epoch' in log:\n",
        "            log['Info/epoch'] = copy.deepcopy(log['epoch'])\n",
        "            del log['epoch']\n",
        "        log['Info/Mode'] = 'train'\n",
        "        log['Info/Progress'] = progress_str(15, 0)\n",
        "        log['Info/Time'] = str(self.timer)\n",
        "        self.pbar.update(log)\n",
        "        self.pbar.update(trainer.logged_metrics)\n",
        "\n",
        "    def on_train_epoch_end(self, *args, **kwargs):\n",
        "        super().on_train_epoch_end(*args, **kwargs)\n",
        "        trainer = args[0]\n",
        "        log = copy.deepcopy(trainer.logged_metrics)\n",
        "        if 'epoch' in log:\n",
        "            log['Info/epoch'] = copy.deepcopy(log['epoch'])\n",
        "            del log['epoch']\n",
        "        log['Info/Mode'] = 'train'\n",
        "        log['Info/Progress'] = progress_str(15, 1.0)\n",
        "        log['Info/Time'] = str(self.timer)\n",
        "        self.pbar.update(log)\n",
        "        self.pbar.update(trainer.logged_metrics)\n",
        "\n",
        "    def on_train_batch_end(self, *args, **kwargs):\n",
        "        super().on_train_batch_end(*args, **kwargs)\n",
        "        self.timer.update(float(self.train_batch_idx)/float(self.total_train_batches))\n",
        "        trainer = args[0]\n",
        "        log = copy.deepcopy(trainer.logged_metrics)\n",
        "        if 'epoch' in log:\n",
        "            log['Info/epoch'] = copy.deepcopy(log['epoch'])\n",
        "            del log['epoch']\n",
        "        log['Info/Mode'] = 'train'\n",
        "        log['Info/Progress'] = progress_str(15, float(self.train_batch_idx)/float(self.total_train_batches)) + ' ' + str(self.train_batch_idx) + ' / ' + str(self.total_train_batches)\n",
        "        log['Info/Time'] = str(self.timer)\n",
        "        self.pbar.update(log)\n",
        "\n",
        "    def on_validation_epoch_start(self, *args, **kwargs):\n",
        "        super().on_validation_epoch_start(*args, **kwargs)\n",
        "        self.timer.reset()\n",
        "        trainer = args[0]\n",
        "        log = trainer.logged_metrics\n",
        "        if 'epoch' in log:\n",
        "            log['Info/epoch'] = copy.deepcopy(log['epoch'])\n",
        "            del log['epoch']\n",
        "        log['Info/Mode'] = 'val'\n",
        "        log['Info/Progress'] = progress_str(15, 0)\n",
        "        log['Info/Time'] = str(self.timer)\n",
        "        self.pbar.update(log)\n",
        "        self.pbar.update(trainer.logged_metrics)\n",
        "\n",
        "    def on_validation_epoch_end(self, *args, **kwargs):\n",
        "        super().on_validation_epoch_end(*args, **kwargs)\n",
        "        trainer = args[0]\n",
        "        log = copy.deepcopy(trainer.logged_metrics)\n",
        "        if 'epoch' in log:\n",
        "            log['Info/epoch'] = copy.deepcopy(log['epoch'])\n",
        "            del log['epoch']\n",
        "        log['Info/Mode'] = 'val'\n",
        "        log['Info/Progress'] = progress_str(15, 1.0)\n",
        "        log['Info/Time'] = str(self.timer)\n",
        "        self.pbar.update(log)\n",
        "        self.pbar.update(trainer.logged_metrics)\n",
        "\n",
        "    def on_validation_batch_end(self, *args, **kwargs):\n",
        "        super().on_validation_batch_end(*args, **kwargs)\n",
        "        self.timer.update(float(self.val_batch_idx)/float(self.total_val_batches))\n",
        "        trainer = args[0]\n",
        "        log = copy.deepcopy(trainer.logged_metrics)\n",
        "        if 'epoch' in log:\n",
        "            log['Info/epoch'] = copy.deepcopy(log['epoch'])\n",
        "            del log['epoch']\n",
        "        log['Info/Mode'] = 'val'\n",
        "        log['Info/Progress'] = progress_str(15, float(self.val_batch_idx)/float(self.total_val_batches)) + ' ' + str(self.val_batch_idx) + ' / ' + str(self.total_val_batches)\n",
        "        log['Info/Time'] = str(self.timer)\n",
        "        self.pbar.update(log)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q pytorch-lightning==1.9.5\n",
        "!pip install -q wandb"
      ],
      "metadata": {
        "id": "40HM1zhMCWwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90bf453b-ab87-484d-fe7f-6c8aa2d8797f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pytorch_lightning.loggers import WandbLogger\n",
        "# import datetime\n",
        "\n",
        "# model = PLModel(VGG())\n",
        "\n",
        "# logger = WandbLogger(\n",
        "#     name=type(model.model).__name__,\n",
        "#     project='CIFAR10-class',\n",
        "#     version=str(datetime.datetime.now()).replace(':', '-'),\n",
        "#     log_model=False)\n",
        "\n",
        "# trainer = pl.Trainer(\n",
        "#     gpus=1,\n",
        "#     logger=logger,\n",
        "#     callbacks=[LiteProgressBar()])\n",
        "\n",
        "# trainer.fit(\n",
        "#     model, train_loader,\n",
        "#     val_dataloaders=test_loader)"
      ],
      "metadata": {
        "id": "mfYEqg1cB9C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import datetime\n",
        "\n",
        "model = PLModel(ResNet())\n",
        "\n",
        "logger = WandbLogger(\n",
        "    name=type(model.model).__name__,\n",
        "    project='CIFAR10-class',\n",
        "    version=str(datetime.datetime.now()).replace(':', '-'),\n",
        "    log_model=False)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    logger=logger,\n",
        "    callbacks=[LiteProgressBar()])\n",
        "\n",
        "trainer.fit(\n",
        "    model, train_loader,\n",
        "    val_dataloaders=test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "XnJ--iYNPO2V",
        "outputId": "bc8d885c-0339-49ea-91e9-34fd8c4e1945"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjimsn94\u001b[0m (\u001b[33mjimteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20230622_022947-2023-06-22 02-29-42.924202</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jimteam/CIFAR10-class/runs/2023-06-22%2002-29-42.924202' target=\"_blank\">ResNet</a></strong> to <a href='https://wandb.ai/jimteam/CIFAR10-class' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jimteam/CIFAR10-class' target=\"_blank\">https://wandb.ai/jimteam/CIFAR10-class</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jimteam/CIFAR10-class/runs/2023-06-22%2002-29-42.924202' target=\"_blank\">https://wandb.ai/jimteam/CIFAR10-class/runs/2023-06-22%2002-29-42.924202</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "  rank_zero_deprecation(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  rank_zero_warn(\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type   | Params\n",
            "---------------------------------\n",
            "0 | model | ResNet | 2.2 M \n",
            "---------------------------------\n",
            "2.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.2 M     Total params\n",
            "8.655     Total estimated model params size (MB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ep0 <- display_id\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "\u001b[1;31m train_loss_step \u001b[0;0m0.41330546                                                                         \n",
              "\u001b[1;32m            Info \u001b[0;0m\u001b[3;32mMode\u001b[0;0m: train | \u001b[3;32mProgress\u001b[0;0m: [======9        ] 727 / 1562 | \u001b[3;32mTime\u001b[0;0m: [0:00:33>0:00:39]     \n",
              "\u001b[1;33m    val_accuracy \u001b[0;0m0.8516                                                                             \n",
              "\u001b[1;34mtrain_loss_epoch \u001b[0;0m0.40029183                                                                         \n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "\u001b[1;31m train_loss_step \u001b[0;0m0.13934995                                                                         \n",
              "\u001b[1;32m            Info \u001b[0;0m\u001b[3;32mMode\u001b[0;0m: train | \u001b[3;32mProgress\u001b[0;0m: [============0  ] 1253 / 1562 | \u001b[3;32mTime\u001b[0;0m: [0:01:00>0:00:14]    \n",
              "\u001b[1;33m    val_accuracy \u001b[0;0m0.8879                                                                             \n",
              "\u001b[1;34mtrain_loss_epoch \u001b[0;0m0.24905005                                                                         \n",
              "===================================================================================================="
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "try:\n",
        "    wandb.init()\n",
        "    print(\"wandb is installed and imported successfully.\")\n",
        "except ImportError:\n",
        "    print(\"wandb is not installed. Please install it using !pip install wandb.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495,
          "referenced_widgets": [
            "b846c7c7eddd4933b264798def0f03dd",
            "3b8c26506b044e44913899cea4ff669d",
            "43577881ee9c4dc2ab93b5dfe4dfc960",
            "5c6c71f3d9b14b1eab42ef20e7c527a5",
            "388ae663c6404fd4bb957b37f6256140",
            "9c6d5994aab54f57aed589523fc64475",
            "c53a5bcb70f944d1b175745b02948407",
            "49fa7941c9c74dfaaa33cd08cb68cb23"
          ]
        },
        "id": "svdWR9jXCVW8",
        "outputId": "9ce2dd8c-0232-4754-863b-d98a24753a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:2023-06-22 02-29-42.924202) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b846c7c7eddd4933b264798def0f03dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▇▄▇▅▃▄▄▃▃▃▄▁▂▂▂▂▂▄▄▃▃▃▂▁▂▂▂▂▁▂▁▂▁▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_accuracy</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▇▇█████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>27</td></tr><tr><td>train_loss_epoch</td><td>0.24905</td></tr><tr><td>train_loss_step</td><td>0.05174</td></tr><tr><td>trainer/global_step</td><td>43399</td></tr><tr><td>val_accuracy</td><td>0.8879</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ResNet</strong> at: <a href='https://wandb.ai/jimteam/CIFAR10-class/runs/2023-06-22%2002-29-42.924202' target=\"_blank\">https://wandb.ai/jimteam/CIFAR10-class/runs/2023-06-22%2002-29-42.924202</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230622_022947-2023-06-22 02-29-42.924202/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:2023-06-22 02-29-42.924202). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230622_030846-42cuxb6i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jimteam/uncategorized/runs/42cuxb6i' target=\"_blank\">avid-sunset-4</a></strong> to <a href='https://wandb.ai/jimteam/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jimteam/uncategorized' target=\"_blank\">https://wandb.ai/jimteam/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jimteam/uncategorized/runs/42cuxb6i' target=\"_blank\">https://wandb.ai/jimteam/uncategorized/runs/42cuxb6i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wandb is installed and imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "try:\n",
        "    wandb.init()\n",
        "    print(\"wandb is installed and imported successfully.\")\n",
        "except ImportError:\n",
        "    print(\"wandb is not installed. Please install it using !pip install wandb.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "qKwwl-1mptrn",
        "outputId": "be167c4a-4929-4908-dde4-f4293a2481c1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230624_090707-cnhrmtac</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jimteam/uncategorized/runs/cnhrmtac' target=\"_blank\">olive-dream-5</a></strong> to <a href='https://wandb.ai/jimteam/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jimteam/uncategorized' target=\"_blank\">https://wandb.ai/jimteam/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jimteam/uncategorized/runs/cnhrmtac' target=\"_blank\">https://wandb.ai/jimteam/uncategorized/runs/cnhrmtac</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wandb is installed and imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import datetime\n",
        "\n",
        "model = PLModel(GRU_VGG())\n",
        "\n",
        "logger = WandbLogger(\n",
        "    name=type(model.model).__name__,\n",
        "    project='CIFAR10-class',\n",
        "    version=str(datetime.datetime.now()).replace(':', '-'),\n",
        "    log_model=False)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    logger=logger,\n",
        "    callbacks=[LiteProgressBar()])\n",
        "\n",
        "trainer.fit(\n",
        "    model, train_loader,\n",
        "    val_dataloaders=test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "zBX2g8r5pmyP",
        "outputId": "8fc813e6-fa51-4010-deaf-cd7902b2617c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
            "  rank_zero_deprecation(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
            "  rank_zero_warn(\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type    | Params\n",
            "----------------------------------\n",
            "0 | model | GRU_VGG | 6.2 M \n",
            "----------------------------------\n",
            "6.2 M     Trainable params\n",
            "0         Non-trainable params\n",
            "6.2 M     Total params\n",
            "24.790    Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep0 <- display_id\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "\u001b[1;31m train_loss_step \u001b[0;0m0.60774714                                                                         \n",
              "\u001b[1;32m            Info \u001b[0;0m\u001b[3;32mMode\u001b[0;0m: train | \u001b[3;32mProgress\u001b[0;0m: [=============2 ] 1381 / 1562 | \u001b[3;32mTime\u001b[0;0m: [0:01:32>0:00:12]    \n",
              "\u001b[1;33m    val_accuracy \u001b[0;0m0.775                                                                              \n",
              "\u001b[1;34mtrain_loss_epoch \u001b[0;0m0.62218803                                                                         \n",
              "===================================================================================================="
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNteYQJzOJzs"
      },
      "source": [
        "### 6.1. Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKHQ_y9eIJiV"
      },
      "source": [
        "In this assignment, we will use PyTorch Mobile to deploy the model to a mobile device.\n",
        "\n",
        "In order to rebuild the model for use on the device, you must do the following:\n",
        "\n",
        "1. Put the model in `eval` mode. For the model presented in the task, this is not necessary, but for models that have normalization layers and more complex tricks, it is necessary.\n",
        "\n",
        "2. Simulate example input signal: generate a signal of the same size as the expected signal that will be input to the model in the application. In our case, this will be a tensor of size `1x1x28x28`:\n",
        "     * 1 image\n",
        "     * 1 channel (grayscale)\n",
        "     * 28x28 -- image resolution\n",
        "\n",
        "\n",
        "3. Trace the model using the `torch.jit.trace` method using the generated random input.\n",
        "\n",
        "4. Optimize the traced model for use in mobile devices using the `torch.utils.mobile_optimizer.optimize_for_mobile` method.\n",
        "\n",
        "5. Save the optimized model using the `_save_for_lite_interpreter` method of the model. The final model should be named `model.ptl`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuF1pd1LOQOL"
      },
      "source": [
        "### 6.2. Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPatgdw9ylvM"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "\n",
        "# input_size = (1, 1, 28, 28)\n",
        "# example_input = torch.randn(input_size)\n",
        "# traced_model = torch.jit.trace(model, example_input)\n",
        "# optimized_model = optimize_for_mobile(traced_model)\n",
        "# optimized_model._save_for_lite_interpreter(\"model.ptl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UaEoDPMOWCl"
      },
      "source": [
        "### 6.3. Application assembly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjrjfsSgP0YD"
      },
      "source": [
        "It remains to build the application. Since in this course I am very interested in how exactly the application is written for Android, we will simply add the model to the already finished shell. The application code is available in the Pytorch Mobile Tutorial for [ViT 4 MNIST](https://github.com/pytorch/android-demo-app/blob/master/ViT4MNIST/).\n",
        "\n",
        "The following few lines of code copy the wrapper for the model from github, wrap the model in this wrapper and prepare a zip archive that you just need to download, unpack and run in Android Studio. After that, you can test how the application works in emulators, as well as run it on your phone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-V9forQ07QY"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/pytorch/android-demo-app\n",
        "# !cp ./model.ptl ./android-demo-app/ViT4MNIST/app/src/main/assets/vit4mnist.ptl\n",
        "# !zip -r android.zip ./android-demo-app/ViT4MNIST/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUIaJTJ3scDT"
      },
      "source": [
        "## 7. Application launch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSplGbSXrcLF"
      },
      "source": [
        "In order to test the application on an Android phone, download Android Studio, unpack and open the project. It will be necessary to install component updates and connect your phone. After building and running, you can evaluate how your application works.\n",
        "\n",
        "If you don't have an Android phone, you can use the emulator that comes with Android Studio. Of course, it's not that interesting, but it's better than nothing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwdzJH2osQJ4"
      },
      "source": [
        "## 8. Additional tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uq2YVhdsoM3"
      },
      "source": [
        "The resulting application somehow works. This quite accurately describes the quality of the application, despite the rather high test score. In order to improve the quality of work, you can try the following:\n",
        "\n",
        "1. Instead of a fully connected neural network, use a convolutional one. For example, you can use a fairly simple LeNet architecture\n",
        "\n",
        "2. To further increase the stability of the model, you can use more diverse augmentations. For example, you can use RandomResizedCrop, rotations, adding a little noise."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qWt0iuJbKdwY",
        "leg6cl0LTvgE",
        "0rIczAZDQ5ed",
        "oOotwBlCq1yH",
        "qLB9pVGrdsRP",
        "f_0GI7bIh_oc",
        "qqVoQYo3Fiwe",
        "ALud-qiffruc",
        "bFjF5lk7MFTT",
        "dtOO1GnOOEWj",
        "MS9UeP4eOSCo",
        "H4nE3JOaOeIM",
        "jpP4pHsjg-0Y",
        "38Az-VUQOvAU",
        "JmwyUvjCeWNv",
        "eD-5rFJ0eakB",
        "-9URMzgnyCJa",
        "KNteYQJzOJzs",
        "SuF1pd1LOQOL",
        "FUIaJTJ3scDT"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "625a3e9bb539bddba3637b86871d7600e463f0e3e5553319a9ee64ea984715f3"
      }
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b846c7c7eddd4933b264798def0f03dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b8c26506b044e44913899cea4ff669d",
              "IPY_MODEL_43577881ee9c4dc2ab93b5dfe4dfc960"
            ],
            "layout": "IPY_MODEL_5c6c71f3d9b14b1eab42ef20e7c527a5"
          }
        },
        "3b8c26506b044e44913899cea4ff669d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_388ae663c6404fd4bb957b37f6256140",
            "placeholder": "​",
            "style": "IPY_MODEL_9c6d5994aab54f57aed589523fc64475",
            "value": "0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "43577881ee9c4dc2ab93b5dfe4dfc960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53a5bcb70f944d1b175745b02948407",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49fa7941c9c74dfaaa33cd08cb68cb23",
            "value": 0.9777371656421332
          }
        },
        "5c6c71f3d9b14b1eab42ef20e7c527a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388ae663c6404fd4bb957b37f6256140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c6d5994aab54f57aed589523fc64475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c53a5bcb70f944d1b175745b02948407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49fa7941c9c74dfaaa33cd08cb68cb23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}